# AWS Glue란?

## 개념 정의
AWS Glue는 AWS에서 제공하는 **완전 관리형 서버리스 데이터 통합(ETL) 서비스**다. 여러 데이터 소스에서 데이터를 추출(Extract)하고, 분석에 적합하게 변환(Transform)한 뒤, 목적지로 로드(Load)하는 전체 과정을 자동화·간소화할 수 있다. 70개 이상의 다양한 데이터 소스를 지원하며, 인프라 관리 없이 데이터 파이프라인을 구축할 수 있다.

쉽게 말해 "데이터 레이크·웨어하우스 구축을 위한 AWS의 자동화된 데이터 가공·통합 플랫폼"으로, 복잡한 데이터 처리를 코드 없이 시각적으로 설계하거나 자동 생성된 스크립트로 실행할 수 있다.

## 핵심 특징

**서버리스 아키텍처**
- 인프라 프로비저닝, 관리, 스케일링 모두 AWS가 자동 처리
- 사용한 리소스만큼만 비용 지불, 유휴 시간 비용 없음
- 워크로드에 따라 자동으로 리소스 확장·축소

**메타데이터 기반 자동화**
- 데이터 카탈로그(Data Catalog)에 스키마·메타데이터 중앙 관리
- 크롤러(Crawler)가 데이터 소스를 자동 스캔해 스키마 추론·카탈로그 생성
- 별도 저장소 없이 메타데이터만으로 ETL 작업 수행

**시각적 ETL 파이프라인 설계**
- AWS Glue Studio의 드래그앤드롭 인터페이스로 코드 작성 없이 ETL 작업 구성
- 자동으로 Python/Scala 기반 Apache Spark 스크립트 생성
- 복잡한 데이터 변환 로직도 시각적으로 설계 가능

**다양한 데이터 소스·형식 지원**
- S3, RDS, Redshift, DynamoDB, Kinesis, Kafka 등 70개 이상 데이터 소스 연결
- 정형(CSV, Parquet), 반정형(JSON, XML, AVRO), 스트리밍 데이터 모두 처리
- 온프레미스 JDBC 연결 데이터베이스도 지원

**Apache Spark 기반 고성능**
- 대규모 데이터 처리를 위한 분산 컴퓨팅 엔진
- Dynamic Frame으로 중첩·반정형 데이터 유연하게 처리
- Spark DataFrame과 완벽 호환, 고급 변환 작업 지원

## 주요 구성 요소

**AWS Glue Data Catalog**
- 모든 데이터 소스의 메타데이터(테이블 정의, 스키마, 파티션 등) 중앙 저장소
- Athena, EMR, Redshift Spectrum 등 다른 AWS 서비스와 공유·활용
- 리전당 계정별로 하나의 카탈로그 제공

**Crawler(크롤러)**
- 데이터 소스를 자동 스캔해 스키마·구조 파악
- Data Catalog에 테이블 메타데이터 자동 생성·업데이트
- 스케줄 기반 또는 온디맨드 실행, 스키마 변경 자동 감지

**Job(작업)**
- 실제 ETL 변환 로직을 수행하는 실행 단위
- Python 또는 Scala 스크립트로 작성(자동 생성 또는 직접 작성)
- 트리거(시간, 이벤트, 조건)에 따라 자동 실행

**Classifier(분류자)**
- 데이터 형식(CSV, JSON, Parquet, AVRO, XML 등) 자동 인식
- 사용자 정의 분류자(Grok 패턴) 생성 가능

**Connection(연결)**
- 특정 데이터 스토어(DB, S3 등) 연결 정보(URL, 자격증명, 네트워크) 저장
- VPC 내부 리소스 연결 시 ENI 기반 프라이빗 통신 지원

**Dynamic Frame**
- 중첩·반정형 데이터를 위한 분산 테이블 구조
- 각 레코드가 자체 스키마 포함, 스키마 유연성 극대화
- ETL 고급 변환(ResolveChoice, ApplyMapping 등) 지원

## 전통적 ETL vs AWS Glue 비교

| 특징 | AWS Glue | 전통적 ETL 도구 |
|------|----------|-----------------|
| 인프라 | 서버리스, 관리 불필요 | 서버 구축·운영 필요 |
| 스케일링 | 자동 확장·축소 | 수동 용량 계획 |
| 데이터 카탈로그 | 통합 메타데이터 저장소 | 별도 메타데이터 관리 |
| 개발 방식 | 시각적 편집기+자동 스크립트 | 수동 코딩 |
| 비용 | 사용량 기반 과금 | 라이선스+인프라 비용 |
| AWS 통합 | 네이티브 연동 | 별도 커넥터 필요 |

## 주요 기능

**데이터 검색 및 카탈로그화**
- 크롤러로 여러 데이터 소스 자동 스캔·분류
- 통합 Data Catalog에서 모든 데이터 자산 중앙 관리
- 스키마 버전 관리 및 변경 추적

**시각적 ETL 작업 설계**
- Glue Studio의 노드 기반 인터페이스로 데이터 흐름 설계
- 소스·변환·필터·조인·집계·대상 노드 연결
- 자동 생성된 스크립트 편집·커스터마이징 가능

**스트리밍 데이터 처리**
- Kinesis, Kafka 등 실시간 스트림 데이터 수집·변환
- 마이크로배치 방식으로 초 단위 지연 처리
- 전송 중 데이터 정제·변환 후 대상 저장

**데이터 품질 및 중복 제거**
- FindMatches ML 변환으로 유사·중복 레코드 자동 탐지·병합
- 데이터 품질 규칙 정의 및 검증
- 민감한 데이터(PII) 탐지 및 마스킹

**작업 스케줄링 및 워크플로**
- 시간 기반(cron) 또는 이벤트 기반 트리거
- 작업 체인 구성으로 종속성 있는 ETL 파이프라인 자동화
- EventBridge, Lambda와 연동한 복잡한 워크플로

**모니터링 및 성능 최적화**
- 작업 실행 대시보드로 실시간 모니터링
- CloudWatch Logs/Metrics 통합
- 작업 북마크로 증분 처리·중복 방지

## 주요 활용 사례

**데이터 레이크 구축**
- S3 기반 데이터 레이크에 다양한 소스 데이터 수집·변환·적재
- Parquet, ORC 등 컬럼형 포맷으로 최적화 저장
- Athena, Redshift Spectrum으로 즉시 쿼리 가능

**데이터 웨어하우스 ETL**
- 여러 DB, SaaS 애플리케이션 데이터를 Redshift로 통합
- 스케줄 기반 배치 ETL 파이프라인 자동화
- 증분 데이터만 처리해 비용·시간 절감

**로그·이벤트 데이터 처리**
- CloudTrail, VPC Flow Logs, 애플리케이션 로그 수집·변환
- 실시간 스트리밍 또는 배치로 분석 가능한 형태로 가공
- 보안·규정 준수를 위한 로그 통합 관리

**머신러닝 데이터 준비**
- 학습 데이터 정제·변환·피처 엔지니어링
- SageMaker와 연동한 ML 파이프라인 구축
- 데이터 품질 검증 및 중복 제거

## 기본 워크플로

### 1. 데이터 소스 크롤링
```python
# 크롤러 생성 및 실행(콘솔/CLI/SDK)
# S3 버킷, RDS 테이블 등을 크롤러로 스캔
# Data Catalog에 테이블 메타데이터 자동 생성
```

### 2. ETL 작업 설계
- Glue Studio에서 시각적으로 ETL 작업 생성
- 소스(S3, RDS) → 변환(필터, 조인, 집계) → 대상(Redshift, S3) 노드 연결
- 또는 Python/Scala 스크립트 직접 작성

### 3. 작업 실행 및 스케줄링
```python
# 작업 트리거 설정
# 시간 기반: 매일 자정 실행
# 이벤트 기반: 새 파일 S3 업로드 시 자동 실행
```

### 4. 모니터링 및 디버깅
- Glue 콘솔에서 작업 실행 상태·로그 확인
- CloudWatch로 오류·성능 메트릭 분석
- 작업 북마크로 처리된 데이터 추적

## 비용 구조

**ETL 작업(배치)**
- DPU(Data Processing Unit) 시간당 $0.44
- 1 DPU = 4 vCPU + 16GB 메모리
- 최소 10분 단위 과금, 이후 1초 단위

**스트리밍 ETL**
- DPU 시간당 $0.44(배치와 동일)
- 최소 10분 과금, 이후 1초 단위

**크롤러**
- DPU 시간당 $0.44
- 처음 100만 객체 무료 티어

**Data Catalog**
- 처음 100만 객체 저장 무료
- 100만 객체 초과 시 100만 개당 월 $1
- 처음 100만 요청 무료, 이후 100만 요청당 $1

## 보안 모범 사례

**접근 제어**
- IAM 역할로 Glue 작업·크롤러 권한 최소화
- Data Catalog 리소스 정책으로 계정·조직 간 공유 제어
- Lake Formation으로 테이블·컬럼 수준 세밀한 권한 관리

**데이터 암호화**
- S3 데이터 암호화(SSE-S3, SSE-KMS)
- Glue Data Catalog 암호화(KMS)
- 작업 북마크·로그 암호화

**네트워크 보안**
- VPC 내부 리소스 접근 시 VPC 엔드포인트 사용
- 프라이빗 서브넷의 ENI로 DB 연결
- 보안 그룹으로 네트워크 트래픽 제어

**감사 및 모니터링**
- CloudTrail로 모든 Glue API 호출 기록
- Data Catalog 접근·변경 로그 추적
- CloudWatch 알람으로 작업 실패·성능 저하 감지

AWS Glue는 현대적인 데이터 분석 아키텍처의 핵심으로, 서버리스·자동화·확장성을 통해 복잡한 데이터 통합 작업을 단순화하고 데이터 레이크·웨어하우스 구축을 가속화하는 필수 서비스다.
